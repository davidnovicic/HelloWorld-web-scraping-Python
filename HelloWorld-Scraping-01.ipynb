{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e73179c-5319-4f15-a2bc-94c2afd66584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3fa251-422c-4095-9886-0f7f1e898e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1530,
   "id": "544a4980-9c84-40de-81c9-5476446d5c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=1&disable_saved_search=1\n",
      "Found 30 jobs on page 1\n",
      "Sample title from page 1: Šef IT sektora Polovnih Automobila (Head of Software Development)\n",
      "Total jobs accumulated so far: 30\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=31&disable_saved_search=1\n",
      "Found 30 jobs on page 31\n",
      "Sample title from page 31: Microsoft 365 Analyst\n",
      "Total jobs accumulated so far: 60\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=61&disable_saved_search=1\n",
      "Found 30 jobs on page 61\n",
      "Sample title from page 61: SAP Consultant HCM\n",
      "Total jobs accumulated so far: 90\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=91&disable_saved_search=1\n",
      "Found 30 jobs on page 91\n",
      "Sample title from page 91: Senior Software Developer\n",
      "Total jobs accumulated so far: 120\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=121&disable_saved_search=1\n",
      "Found 30 jobs on page 121\n",
      "Sample title from page 121: Cloud Infrastructure Administrator\n",
      "Total jobs accumulated so far: 150\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=151&disable_saved_search=1\n",
      "Found 30 jobs on page 151\n",
      "Sample title from page 151: Python Tech Lead/ Engineering Manager\n",
      "Total jobs accumulated so far: 180\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=181&disable_saved_search=1\n",
      "Found 30 jobs on page 181\n",
      "Sample title from page 181: Machine Learning Engineering Manager\n",
      "Total jobs accumulated so far: 210\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=211&disable_saved_search=1\n",
      "Found 30 jobs on page 211\n",
      "Sample title from page 211: Senior Fullstack Developer (С#, JS)\n",
      "Total jobs accumulated so far: 240\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=241&disable_saved_search=1\n",
      "Found 30 jobs on page 241\n",
      "Sample title from page 241: Middle PHP Developer\n",
      "Total jobs accumulated so far: 270\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=271&disable_saved_search=1\n",
      "Found 30 jobs on page 271\n",
      "Sample title from page 271: Lead Game Developer - Paper.io 2\n",
      "Total jobs accumulated so far: 300\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=301&disable_saved_search=1\n",
      "Found 30 jobs on page 301\n",
      "Sample title from page 301: Head of Engineering - Trading\n",
      "Total jobs accumulated so far: 330\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=331&disable_saved_search=1\n",
      "Found 30 jobs on page 331\n",
      "Sample title from page 331: Lead Business Analyst\n",
      "Total jobs accumulated so far: 360\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=361&disable_saved_search=1\n",
      "Found 30 jobs on page 361\n",
      "Sample title from page 361: Senior React Developer\n",
      "Total jobs accumulated so far: 390\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=391&disable_saved_search=1\n",
      "Found 30 jobs on page 391\n",
      "Sample title from page 391: Mobile Developer (Andriod/iOS)\n",
      "Total jobs accumulated so far: 420\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=421&disable_saved_search=1\n",
      "Found 30 jobs on page 421\n",
      "Sample title from page 421: Middle/Senior Data Analyst\n",
      "Total jobs accumulated so far: 450\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=451&disable_saved_search=1\n",
      "Found 30 jobs on page 451\n",
      "Sample title from page 451: Tax & Treasury Manager\n",
      "Total jobs accumulated so far: 480\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=481&disable_saved_search=1\n",
      "Found 30 jobs on page 481\n",
      "Sample title from page 481: Strategic Account Executive\n",
      "Total jobs accumulated so far: 510\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=511&disable_saved_search=1\n",
      "Found 30 jobs on page 511\n",
      "Sample title from page 511: Compiler Developer (LLVM, C++)\n",
      "Total jobs accumulated so far: 540\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=541&disable_saved_search=1\n",
      "Found 30 jobs on page 541\n",
      "Sample title from page 541: Frontend Engineer\n",
      "Total jobs accumulated so far: 570\n",
      "Scraping from https://www.helloworld.rs/oglasi-za-posao?page=571&disable_saved_search=1\n",
      "Found 23 jobs on page 571\n",
      "Sample title from page 571: Senior Systems Engineer\n",
      "Total jobs accumulated so far: 593\n",
      "Excel done\n",
      "Total unique jobs scraped: 593\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "\n",
    "# Initialize an empty DataFrame to accumulate all data\n",
    "data_frame = pd.DataFrame()\n",
    "\n",
    "# Starting page and increment\n",
    "START_PAGE = 1\n",
    "PAGE_INCREMENT = 30\n",
    "MAX_PAGES = 20  # Adjust this to scrape more pages (e.g., 5 for page=1, 30, 60, 90, 120...)\n",
    "\n",
    "for page_num in range(MAX_PAGES):\n",
    "    titles = []\n",
    "    urls = []\n",
    "    descriptions = []\n",
    "    locations = []\n",
    "\n",
    "    # Calculate the page value (1, 30, 60, etc.)\n",
    "    page_value = START_PAGE + (page_num * PAGE_INCREMENT)\n",
    "    if page_num == 0:  # Ensure first page is page=1, not page=0\n",
    "        page_value = START_PAGE\n",
    "\n",
    "    HEADERS = {\"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:137.0) Gecko/20100101 Firefox/137.0\"}\n",
    "    \n",
    "    # Use the page value in the URL\n",
    "    search_url = f\"https://www.helloworld.rs/oglasi-za-posao?page={page_value}&disable_saved_search=1\"\n",
    "    print(f\"Scraping from {search_url}\")\n",
    "\n",
    "    # Fetch the page\n",
    "    response = requests.get(search_url, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch page {page_value} with status code: {response.status_code}\")\n",
    "        continue\n",
    "    \n",
    "    soup = bs(response.text, 'html.parser')\n",
    "\n",
    "    # Check if jobs container exists\n",
    "    get_info = soup.find(\"div\", class_=\"max-w-5xl mx-auto flex flex-col gap-4 mb-8 __search-results\")\n",
    "    if not get_info:\n",
    "        print(f\"No job container found on page {page_value}\")\n",
    "        continue\n",
    "\n",
    "    # Get job titles, URLs, location and description\n",
    "    get_job_titles = get_info.find_all('h3')\n",
    "    get_job_urls = get_info.find_all('a', class_=\"__ga4_job_title hover:opacity-50 font-bold text-lg\")\n",
    "    get_job_location = get_info.find_all('div', class_=\"flex flex-col gap-4 flex-1 px-4 md:pl-4 mb-4 w-full\")\n",
    "    get_job_des = get_info.find_all('div', class_=\"flex flex-col gap-4 flex-1 px-4 md:pl-4 mb-4 w-full\")\n",
    "\n",
    "    min_length = min(len(get_job_titles), len(get_job_urls), len(get_job_des))\n",
    "    print(f\"Found {min_length} jobs on page {page_value}\")\n",
    "\n",
    "    for i in range(min_length):\n",
    "        # Title\n",
    "        try:\n",
    "            title = get_job_titles[i].text.strip()\n",
    "        except:\n",
    "            title = \"\"\n",
    "        titles.append(title)\n",
    "\n",
    "        # URL\n",
    "        try:\n",
    "            url = \"https://helloworld.rs\" + get_job_urls[i]['href']\n",
    "        except:\n",
    "            url = \"\"\n",
    "        urls.append(url)\n",
    "\n",
    "        # Location\n",
    "        try:\n",
    "            location = get_job_location[i]('p')[0]\n",
    "        except:\n",
    "            locations = \"\"\n",
    "        locations.append(locations)\n",
    "\n",
    "        # Description\n",
    "        try:\n",
    "            des = get_job_des[i]('p')[1].text\n",
    "        except:\n",
    "            des = \"\"\n",
    "        descriptions.append(des)\n",
    "        \n",
    "\n",
    "    # Debugging: Print a sample to verify uniqueness\n",
    "    if titles:\n",
    "        print(f\"Sample title from page {page_value}: {titles[0]}\")\n",
    "\n",
    "    # Create a temporary DataFrame for this page\n",
    "    temp_df = pd.DataFrame({\n",
    "        \"titles\": titles,\n",
    "        \"urls\": urls,\n",
    "        \"location\": location,\n",
    "        \"descriptions\": descriptions\n",
    "    })\n",
    "    \n",
    "    # Append to main DataFrame\n",
    "    data_frame = pd.concat([data_frame, temp_df], ignore_index=True)\n",
    "    print(f\"Total jobs accumulated so far: {len(data_frame)}\")\n",
    "\n",
    "    # Add a small delay to avoid overwhelming the server\n",
    "    time.sleep(1)\n",
    "\n",
    "# Save all accumulated data to CSV\n",
    "data_frame.to_csv('HelloWorld.csv', index=False, encoding='utf-8')\n",
    "print('Excel done')\n",
    "print(f\"Total unique jobs scraped: {len(data_frame.drop_duplicates())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc8f09-672f-426c-9858-2269b805de31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10425c55-1f34-4858-995f-c2c58d3e46e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81576520-eb86-40b9-ab70-04c2d0747ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4180a3bd-d536-47a5-99ac-1fddc0bd55c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a90747c-0668-4268-913a-847038ae1f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4ea58-e667-47b8-afc3-18e9f6d3346a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
